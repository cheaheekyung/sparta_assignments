{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('housingdata.csv')\n",
    "df.head()\n",
    "df.tail() #데이터셋 끝부분에도 데이터가 있는지 확인\n",
    "df.shape\n",
    "df.info() #문자열 데이터 없음 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 유무 확인 (총 6개의 열에 각 20개씩 결측치가 존재함)\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "결측치 처리방법\n",
    " 1. 삭제 -> 데이터셋이 적어서 삭제할 경우 데이터 수가 너무 적어짐\n",
    " 2. 대체 -> 보통 이상치의 영향을 덜 받는 중앙값으로 대체 (평균은 이상치의 영향을 많이 받음 like 조던 연봉)\n",
    " 3. 예측 -> 회귀모델 사용하여 예측하여 대체\n",
    "'''\n",
    "#결측치 중앙값으로 대체하기\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(df_imputed)\n",
    "print(np.sum(np.isnan(df_imputed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.5187699604533358\n",
      "p-value: 7.241262860650192e-88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heeky\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 7084.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이상치 처리방법\n",
    "\n",
    "1. 이상치 탐지 \n",
    "    1) IQR : 1사분위수와 3사분위수 사이의 범위(가운데 50%). 일반적으로 ±IQR *1.5를 이상치로 판단\n",
    "    2) Z-score : 평균에서 얼마나 떨어져있는지 확인. 일반적으로 Z-score ±3을 이상치로 판단\n",
    "    선택 기준 : 데이터가 정규분포를 따르면 Z-score가 유리 / 비정규분포이거나 왜곡된 분포면 IQR이 유리\n",
    "\n",
    "2. 이상치 처리\n",
    "    - 이상치 탐지방법 선택을 위해 정규분포를 따르는지 확인\n",
    "        - 시각화 한 후 확인. 정규분포를 따른다면 종모양 히스토그램이 나타남\n",
    "        - 통계적 검정 확인 : p-value가 0.05 이상이면 정규성을 따르는 것으로 간주\n",
    "'''\n",
    "\n",
    "#통계적 검정 확인(Shapiro-Wilk Test)\n",
    "from scipy.stats import shapiro\n",
    "stat, p_value = shapiro(df_imputed)\n",
    "print(\"Test Statistic:\", stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "'''\n",
    "test statistic 값이 1과 가까우면 정규분포로 볼 수 있으나 약 0.52으로 멀리 떨어져있음.\n",
    "p-value는 0.05보다 크면 정규분포로 간주하는데, 7.241262860650192e-88로 매우 작음.\n",
    "즉, 해당 데이터는 비정규분포로 IQR 이상치 탐지를 활용하여 처리하는 것이 유리하다고 판단 됨.\n",
    "'''\n",
    "\n",
    "#IQR 이상치 탐지\n",
    "Q1 = np.quantile(df_imputed, 0.25, axis=0)\n",
    "Q3 = np.quantile(df_imputed, 0.75, axis=0)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "#IQR 1.5배 이상치 처리\n",
    "outliers = ((df_imputed < (Q1 - 1.5 * IQR)) | (df_imputed > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "#print(outliers.sum())\n",
    "\n",
    "#이상치 삭제\n",
    "df_cleaned = pd.DataFrame(df_imputed[~outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#독립변수(X), 종속변수(y) 분리\n",
    "X = df_cleaned.drop('MEDV' , axis=1)\n",
    "y = df_cleaned['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train데이터와 test데이터 분리\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting\n",
    "    y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# 모델 학습 및 평가 (Pipeline 활용)\n",
    "for name, model in models.items():\n",
    "    # Pipeline 생성\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # 데이터 스케일링\n",
    "        ('model', model)               # 모델 적용\n",
    "    ])\n",
    "    \n",
    "    # 교차 검증 실행\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # 최종 학습 및 예측\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # 결과 저장\n",
    "    results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'CV_R2_mean': cv_scores.mean(),\n",
    "        'CV_R2_std': cv_scores.std()\n",
    "    }\n",
    "\n",
    "# 결과 출력\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name} 결과:\")\n",
    "    print(f\"RMSE: {result['RMSE']:.2f}\")\n",
    "    print(f\"R2 Score: {result['R2']:.2f}\")\n",
    "    print(f\"Cross-validation R2: {result['CV_R2_mean']:.2f} (+/- {result['CV_R2_std'] * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "metrics = ['RMSE', 'R2', 'CV_R2_mean']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[model][metric] for model in results.keys()]\n",
    "    axes[i].bar(results.keys(), values)\n",
    "    axes[i].set_title(metric)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
